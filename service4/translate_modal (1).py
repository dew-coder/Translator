# -*- coding: utf-8 -*-
"""Translate_modal

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aFRmhNT0mvvauheDKFJH5Oj7F80xOgKx
"""

!pip install git+https://github.com/huggingface/transformers -q

!pip install sentencepiece

from transformers import MBartForConditionalGeneration, MBart50TokenizerFast

from bs4 import BeautifulSoup

model = MBartForConditionalGeneration.from_pretrained("facebook/mbart-large-50-one-to-many-mmt")

tokenizer = MBart50TokenizerFast.from_pretrained("facebook/mbart-large-50-one-to-many-mmt", src_lang="en_XX")

def translate_html_text(html_text, target_lang):
    soup = BeautifulSoup(html_text, 'html.parser')
    translated_html = str(soup)

    for tag in soup.find_all():
        if tag.string:
            text_to_translate = tag.string
            model_inputs = tokenizer(text_to_translate, return_tensors="pt")
            generated_tokens = model.generate(
                **model_inputs,
                forced_bos_token_id=tokenizer.lang_code_to_id[target_lang]
            )
            translated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]
            translated_html = translated_html.replace(text_to_translate, translated_text)

    return translated_html

pip install modelbit

def predict(data):
    html_text = data.get('html_text')
    target_lang = data.get('target_lang', 'hi_IN')
    return {'translated_html': translate_html_text(html_text, target_lang)}

import modelbit

mb = modelbit.login()
deployment = mb.deploy(predict)

print("Model deployed successfully!")
print(f"Endpoint: {deployment}")

